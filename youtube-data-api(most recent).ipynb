{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Collection\n",
    "\n",
    "First, we lay out some methods in order to treat our Youtube Data API keys as though they are being fed through a revolving door. If we run queries with an API object built from just one key, we hit quota limits that block us from downloading more information and the program crashes, destroying our data. With our system, an API object is built from the first key in the pool of API keys. When the program encounters an HTTP Error from Google, a new API object is built from the next key in the pool. The new object is passed back to the method running queries and the method carries on making requests to the API. The API keys are a bit like ammunition because once they've exhausted their allocated bandwith from Google, they are useless for the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient.discovery import build\n",
    "from apiclient import errors\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "# Author: Jared Prior, Cedric Blaise\n",
    "\n",
    "# API Revolving Door \n",
    "# intercepts rejected API requests and spins \n",
    "# up a new Youtube build using the next API\n",
    "# key in the pool. The rejected key is discarded\n",
    "# and not considered again, as the revolving\n",
    "# door only dispenses each API key from the \n",
    "# pool once.\n",
    "current_key = 0\n",
    "api_revolving_door = [\"AIzaSyCCCQsP3NGY9rGvOBI5unIvEy4OsAC41tc\", #1\n",
    "                      \"AIzaSyCPqYMsq1HOeOSaLtBGejUh5-GzOKDV8lg\", #2\n",
    "                      \"AIzaSyCGEBtZPu5Bpfa-wJIMcE6QPnzIYiNwD5k\", #3\n",
    "                      'AIzaSyB2VjIO1qBKtHIYfM1kLGK0X4huo5cPgJg', #4\n",
    "                      'AIzaSyDBAlVzk0Q_pqFqdxdosJ09AjS9RhN1o28', #5\n",
    "                      'AIzaSyAQBq0X5Q3JCwwAlqx7hP24x0tS6NYpZpE', #6\n",
    "                      'AIzaSyAQBq0X5Q3JCwwAlqx7hP24x0tS6NYpZpE', #7\n",
    "                      'AIzaSyDbQTp-qKJP55kAAEgXP2vD80uHK4fVG-s', #8\n",
    "                      'AIzaSyBmFEUq7B52ei7WYnlRbY2biTcNkEEIwsM', #9\n",
    "                      \"AIzaSyDbvMLfe7FPhCCycAcKQxWB2urU3SOD0qM\", #10\n",
    "                      \"AIzaSyBMlUoxwkfP2PIjIgDRCe7ladBN6efLgzw\", #11\n",
    "                      'AIzaSyA1Y_LCB5KCU6kZBJVZlHXSvmbNjGiitfY', #12\n",
    "                      'AIzaSyBlqtXeEgvyJGaw5h0SRxWO_ibw_JWX42s', #13\n",
    "                      \"AIzaSyCmXJ4LrPH9IPyw_CyPbmZF2947j6rBcIY\", #14\n",
    "                      \"AIzaSyBU3Hg6Ph7a-z-Dgh1eJ9tHjgDfAonxlyw\", #15\n",
    "                      \"AIzaSyDmKGvWEZzfJKo9QS0CAovzYCLZE3MpF7w\", #16\n",
    "                      \"AIzaSyAKbiwdli7mrYm-5Hcnl356PB8rGam8fB0\", #17\n",
    "                      \"AIzaSyCfm7NmDGTRfuxMK6hMABJYoKdTRGZh-Jk\", #18\n",
    "                      \"AIzaSyCfm7NmDGTRfuxMK6hMABJYoKdTRGZh-Jk\", #19\n",
    "                      \"AIzaSyAXGe4C55z3hL8Znu2vKkQzjUaV0HgWfhs\", #20\n",
    "                      \"AIzaSyCPj4BPl3XcqR8L1GMEblZKKJds3hVIKm8\", #21\n",
    "                      \"AIzaSyACcJRNByz_GLpvZGrdl5RjCtJiH2UGDbo\", #22\n",
    "                      \"AIzaSyDEJYq2pJr6C-czt_jv4g5lf3ni3gharLA\", #23\n",
    "                      \"AIzaSyCMDeQQJogAafO9r3t3yp0Mnp5Spk4K1WU\",\n",
    "                      \"AIzaSyCFo4tjFT1Mv5I6tF6Gm3JbDjlv4rjXefY\", \n",
    "                      \"AIzaSyBn0Ad5kaZx2eyArelLLMKNjDSg4ogZ2SA\", \n",
    "                      \"AIzaSyADUMqQ4Vc4zk208Tax8t0adnFi9nGyi90\"]\n",
    "def yt_build(key):\n",
    "    # builds Youtube object from API key\n",
    "    yt = build(\"youtube\",'v3',developerKey=key) # establishes a connection with the Youtube Data API v3\n",
    "    return yt\n",
    "def door_spin():\n",
    "    global current_key\n",
    "    # retrieves the next build or flags empty pool\n",
    "    if current_key > (len(api_revolving_door)-2):\n",
    "        return None\n",
    "    else:\n",
    "        current_key += 1\n",
    "    print(\"Spinning up new API build: \" + str(current_key))\n",
    "    api_key = api_revolving_door[current_key]\n",
    "    yt = yt_build(api_key)\n",
    "    return yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = yt_build(api_revolving_door[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we craft a function to retrieve comments from any given \n",
    "video by its video ID. This function returns all of the comments in a \n",
    "dictionary, where the comment authors are keys. Each of their comments\n",
    "and their number of likes are stored as the values in a heterogenous list. The video statistics are also retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(video_id, yt):\n",
    "    # retrieves comments from a given Youtube video by its ID\n",
    "    # returns a dictionary of authors and their comments\n",
    "    global current_key\n",
    "    authors = {}\n",
    "    def exists(author_id):\n",
    "        return author_id in authors\n",
    "    stats = yt.videos().list(id=video_id,part=\"statistics\").execute()['items'][0]['statistics']\n",
    "    next_page = None\n",
    "    page = 0\n",
    "    pages = 5\n",
    "    while True:\n",
    "        res = yt.commentThreads().list(videoId=video_id,\n",
    "                                       part=\"snippet,replies\",maxResults=100,pageToken = next_page).execute()\n",
    "\n",
    "        for comment_data in res['items']:\n",
    "            comment_data = comment_data['snippet']['topLevelComment']['snippet']\n",
    "            comment = comment_data['textOriginal']\n",
    "            likes = comment_data['likeCount']\n",
    "            author = comment_data['authorDisplayName']\n",
    "            if exists(author):\n",
    "                authors[author].append([comment,likes])\n",
    "            else:\n",
    "                authors[author] = []\n",
    "                authors[author].append([comment,likes])\n",
    "        next_page = res.get('nextPageToken')\n",
    "        page +=1\n",
    "        if next_page==None or page > pages:\n",
    "            break\n",
    "    return authors, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next function retrieves all of a given channel's Youtube\n",
    "videos and stores each video's video ID, title, date of publishing,\n",
    "its description, and its statistics. It uses the get_video_comments method to \n",
    "create a dictionary of all the comments, and it stores all of these\n",
    "attributes as a heterogenous list within a list of other video-lists. I personally think this method is ugly and I will look into thinning it out and making it more legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_reason(err):\n",
    "    if err.resp.get('content-type', '').startswith('application/json'):\n",
    "        reason = json.loads(err.content).get('error').get('errors')[0].get('reason')\n",
    "    else:\n",
    "        reason=\"Unexplained\"\n",
    "    return reason\n",
    "def channel_videos(channel_id, yt, pages):\n",
    "    # returns all the videos of a particular Youtube\n",
    "    # channel, and returns data for each video (title, description,\n",
    "    # comments, date, statistics, etc.)\n",
    "    global current_key\n",
    "    print(\"Retrieving data for \" + channel_id)\n",
    "    res = None\n",
    "    while res == None:\n",
    "        try:\n",
    "            res = yt.channels().list(id=channel_id,part='contentDetails').execute()\n",
    "        except errors.HttpError as error:\n",
    "            if error_reason(error).split(\" \")[-1] == \"commentsDisabled\":\n",
    "                print(\"Disabled comments: %s\" % error)\n",
    "                pass\n",
    "            elif error.resp.status == 403:\n",
    "                print(\"Error1: %s\" % error)\n",
    "                yt = door_spin()\n",
    "                if yt == None:\n",
    "                    print(\"Breaking\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"Error2: %s\" % error)\n",
    "                pass\n",
    "    items = res['items']\n",
    "    playlist_id = items[0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page = None\n",
    "    page = 0\n",
    "    videos = []\n",
    "    while True:\n",
    "        print(\"Current API index: \" + str(current_key))\n",
    "        try:\n",
    "            result = yt.playlistItems().list(playlistId=playlist_id,part='snippet',maxResults=50,\n",
    "                                             pageToken = next_page).execute()\n",
    "            for res in result['items']:\n",
    "                video_id = res['snippet']['resourceId']['videoId']\n",
    "                video_title = res['snippet']['title']\n",
    "                video_publish_date = res['snippet']['publishedAt']\n",
    "                video_description = res['snippet']['description']\n",
    "                if random.random() > 0.20:\n",
    "                    try:\n",
    "                        authors, stats = get_video_comments(video_id, yt)\n",
    "                        videos.append([video_title, video_publish_date, video_description, stats, authors])\n",
    "                    except errors.HttpError as error:\n",
    "                        if error_reason(error).split(\" \")[-1] == \"commentsDisabled\":\n",
    "                            print(\"Disabled comments: %s\" % error)\n",
    "                            pass\n",
    "                        elif error.resp.status == 403:\n",
    "                            print(\"Error1 inner: %s\" % error)\n",
    "                            yt = door_spin()\n",
    "                            if yt == None:\n",
    "                                print(\"Breaking\")\n",
    "                                return None\n",
    "                        else:\n",
    "                            print(\"Error2: %s\" % error)\n",
    "                            pass\n",
    "            if random.random()>0.80:\n",
    "                next_page = yt.playlistItems().list(playlistId=playlist_id,part='snippet',maxResults=50,\n",
    "                pageToken = result.get('nextPageToken')).execute().get('nextPageToken')\n",
    "            else:\n",
    "                next_page = result.get('nextPageToken')\n",
    "                page += 1\n",
    "                print(\"Current page: \" + str(page))\n",
    "        except errors.HttpError as error:\n",
    "            if error_reason(error).split(\" \")[-1] == \"commentsDisabled\":\n",
    "                print(\"Disabled comments: %s\" % error)\n",
    "                pass\n",
    "            elif error.resp.status == 403:\n",
    "                print(\"Error1 outer: %s\" % error)\n",
    "                yt = door_spin()\n",
    "                if yt == None:\n",
    "                    print(\"Breaking\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"Error2: %s\" % error)\n",
    "                continue\n",
    "        if next_page == None or page > pages:\n",
    "            break\n",
    "        print(str(len(videos)) + \" videos retrieved from the API so far\")\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some channels might appear as a \"user\" instead of a \"channel,\" so we convert those by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_id = yt.channels().list(part=\"id\",forUsername='CNN').execute()['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_id = yt.channels().list(part=\"id\",forUsername='FoxNewsChannel').execute()['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_times_id = yt.channels().list(part=\"id\",forUsername='TheNewYorkTimes').execute()['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msnbc_id = yt.channels().list(part=\"id\",forUsername='msnbcleanforward').execute()['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breitbart_id = \"UCmgnsaQIK1IR808Ebde-ssA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we retrieve the videos using our channel IDs and our channel_videos method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_data = channel_videos(cnn_id, yt, 20) # left wing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fox_data = channel_videos(fox_id, yt, 20) # right wing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_times_data = channel_videos(ny_times_id, yt, 20) # left wing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msnbc_data = channel_videos(msnbc_id, yt, 20) # left wing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breitbart_data = channel_videos(breitbart_id, yt, 20) # alt right "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Caching\n",
    "We will now process our data and organize it so that \n",
    "it may be used for analysis. We will also cache our data\n",
    "at this point, since Google restricts the number of requests\n",
    "we can make with the API and we want to make the most of\n",
    "every request we are allowed. It also takes a frustratingly long\n",
    "time to make the requests and store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_channel_data(data, channel):\n",
    "    channel_file = open(channel +\".txt\",\"w\")\n",
    "    channel_file.write(str(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will include an unpackaging \n",
    "method so that we can retrieve the data from our text files\n",
    "in the same format as it is returned in the channel_videos\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_cached_data(channel):\n",
    "    print(\"Unpacking data: \", channel)\n",
    "    channel_file = open(channel, \"r\")\n",
    "    cached_data = channel_file.read()\n",
    "    videos = ast.literal_eval(cached_data)\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use our caching function to dump our data to text files. We can use the unpacking method to retrieve all the data in its pre-cache format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_channel_data(cnn_data, \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_channel_data(fox_data, \"Fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_channel_data(breitbart_data, \"Breitbart News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_channel_data(ny_times_data, \"NYTimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_channel_data(msnbc_data, \"MSNBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucnn_data = unpack_cached_data(\"CNN.txt\")\n",
    "ufox_data = unpack_cached_data(\"Fox.txt\")\n",
    "ubreitbart_data = unpack_cached_data(\"Breitbart News.txt\")\n",
    "umsnbc_data = unpack_cached_data(\"MSNBC.txt\")\n",
    "uny_times_data = unpack_cached_data(\"NYTimes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Processing and Organization\n",
    "We'll write a function to process the statistics for each video and return the number of views, likes, dislikes, and comments. But first we will need some helper methods to help us convert the video dates and timestamps to the proper format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def convert_raw_date(date):\n",
    "    date_raw = date.split(\"T\")[0].split(\"-\")\n",
    "    year = int(date_raw[0])\n",
    "    month = int(date_raw[1])\n",
    "    day = int(date_raw[2])\n",
    "    return year, month, day\n",
    "def to_integer(dt_time):\n",
    "    return 10000*dt_time.year + 100*dt_time.month + dt_time.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_stats(video):\n",
    "    title, publish_date, description, stats, authors = video\n",
    "    year, month, day = convert_raw_date(publish_date)\n",
    "    date = datetime.date(year,month,day)\n",
    "    views = stats['viewCount']\n",
    "    likes = stats['likeCount']\n",
    "    dislikes = stats['dislikeCount']\n",
    "    num_comments = stats['commentCount']\n",
    "    return title, date, description, int(views), int(likes), int(dislikes), int(num_comments), authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our processing function to build up lists of different values that we can plot against the publishing dates of each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(videos):\n",
    "    # returns a list of lists where index i in any of the lists\n",
    "    # contains specific information about video i e.g,\n",
    "    # titles[i], like_nums[i] = gives you the title and \n",
    "    # number of likes of video i\n",
    "    like_nums = []\n",
    "    dislike_nums = []\n",
    "    comment_nums = []\n",
    "    dislike_ratios = []\n",
    "    dates = []\n",
    "    titles = []\n",
    "    comments = []\n",
    "    view_nums = []\n",
    "    interactions = []\n",
    "    descriptions = []\n",
    "    for video in videos:\n",
    "        title, date, description, views, likes, dislikes, num_comments, authors=process_video_stats(video)\n",
    "        like_nums.append(likes)\n",
    "        dislike_nums.append(dislikes)\n",
    "        dislike_ratios.append(dislikes/(likes+dislikes))\n",
    "        comment_nums.append(num_comments)\n",
    "        dates.append(date)\n",
    "        titles.append(title)\n",
    "        comments.append(authors)\n",
    "        view_nums.append(views)\n",
    "        interactions.append(num_comments+likes+dislikes)\n",
    "        descriptions.append(description)\n",
    "    return like_nums, dislike_nums, comment_nums, dislike_ratios,\\\n",
    "    dates, titles, comments, view_nums, descriptions, interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can process all of our data so that it is more accessible and easier to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_cnn_data = process_videos(cnn_data)\n",
    "processed_fox_data = process_videos(fox_data)\n",
    "processed_nytimes_data = process_videos(ny_times_data)\n",
    "processed_msnbc_data = process_videos(msnbc_data)\n",
    "processed_breitbart_data = process_videos(breitbart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write some auxiliary functions to help us merge authors amongst all the channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_channel_authors(author_dicts):\n",
    "    author_dict = {}\n",
    "    for authors in author_dicts:\n",
    "        for author in authors:\n",
    "            if author in author_dict:\n",
    "                author_dict[author].append(authors[author])\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_authors(comment_dictionaries):\n",
    "    unique_authors = {}\n",
    "    for video in comments:\n",
    "        for author in video:\n",
    "            if author in unique_authors:\n",
    "                unique_authors[author].append(video[author])\n",
    "            else:\n",
    "                unique_authors[author] = []\n",
    "                unique_authors[author].append(video[author])\n",
    "    return unique_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(y, title):\n",
    "    file=open(title,\"w\")\n",
    "    for x in y:\n",
    "        file.write(x + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Analysis and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now write a plotting function to plot based on the metrics we've produced from our processing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "%matplotlib inline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import datetime\n",
    "from matplotlib.dates import WeekdayLocator\n",
    "from matplotlib.dates import DayLocator\n",
    "from matplotlib.dates import (YEARLY, DateFormatter,rrulewrapper, RRuleLocator, drange)\n",
    "from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n",
    "import statistics\n",
    "def plot_data(data, dates, title):\n",
    "    mpl.rcParams['figure.dpi'] = 150\n",
    "    loc = DayLocator(interval=30)\n",
    "    formatter = DateFormatter('%Y-%m-%d')\n",
    "    fig, ax = plt.subplots()\n",
    "    y_mean = statistics.mean(data)\n",
    "    st=\"{:.2f}\".format(y_mean)\n",
    "    plt.plot_date(np.array(dates), np.array(data))\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_tick_params(rotation=30, labelsize=10)\n",
    "    plt.axhline(y=y_mean, color='r', linestyle='-',label='Mean Average: {}'.format(float(st)))\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(20,5))\n",
    "    style.use('fivethirtyeight')\n",
    "    plt.show()\n",
    "def plot_datas(data, data2, title):\n",
    "    mpl.rcParams['figure.dpi'] = 150\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    style.use('fivethirtyeight')\n",
    "    plt.scatter(data,data2,s=2)\n",
    "    z = numpy.polyfit(data, data2, 1)\n",
    "    p = numpy.poly1d(z)\n",
    "    #plt.plot(data,p(data),\"r--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function to plot video statistics over time from any given channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[0],processed_cnn_data[4], \"CNN Video Likes\")\n",
    "plot_data(processed_fox_data[0],processed_fox_data[4], \"FOX News Video Likes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[1],processed_cnn_data[4], \"CNN Video Dislikes\")\n",
    "plot_data(processed_fox_data[1],processed_fox_data[4], \"FOX News Video Dislikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[3],processed_cnn_data[4], \"CNN Video Dislikes/Total\")\n",
    "plot_data(processed_fox_data[3],processed_fox_data[4], \"FOX News Video Dislikes/Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[7],processed_cnn_data[4], \"CNN Video Views\")\n",
    "plot_data(processed_fox_data[7],processed_fox_data[4], \"FOX News Video Views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[2],processed_cnn_data[4], \"CNN Video Comments\")\n",
    "plot_data(processed_fox_data[2],processed_fox_data[4], \"FOX News Video Comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(processed_cnn_data[9],processed_cnn_data[4], \"CNN Video Interactions\")\n",
    "plot_data(processed_fox_data[9],processed_fox_data[4], \"FOX News Video Interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we'd like to do a broad sentiment analysis for each channel's videos, we can write some functions to help us do that. We'll loop through our processed data and retrive the comments. For each video, we'll find the mean average positive, negative, and compound sentiment scores by aggregating these scores from each comment in the video. We'll also create an overloaded method for analyzing sentiments towards a specific keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def analyze(comment):\n",
    "    score = analyzer.polarity_scores(comment)\n",
    "    return score[\"compound\"], score[\"pos\"], score[\"neg\"]\n",
    "def analyze_channel(data):\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    compound_scores = []\n",
    "    like_nums, dislike_nums, comment_nums, like_dislike_ratios, dates,\\\n",
    "    titles, comments, view_nums, description, interactions = data\n",
    "    for author_dict in comments: # video comments\n",
    "        vid_pos = []\n",
    "        vid_neg = []\n",
    "        vid_comp = []\n",
    "        for author in author_dict: # all the authors in the comment section\n",
    "            for comment in author_dict[author]: # their comments\n",
    "                comp, pos, neg = analyze(comment[0])\n",
    "                vid_pos.append(pos)\n",
    "                vid_neg.append(neg)\n",
    "                vid_comp.append(comp)\n",
    "        pos = statistics.mean(vid_pos)\n",
    "        neg = statistics.mean(vid_neg)\n",
    "        comp = statistics.mean(vid_comp)\n",
    "        pos_scores.append(pos)\n",
    "        neg_scores.append(neg)\n",
    "        compound_scores.append(comp)\n",
    "    return pos_scores,neg_scores,compound_scores\n",
    "def analyze_channel_by_keyword(data, keyword):\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    compound_scores = []\n",
    "    dates_by_keyword = []\n",
    "    like_nums, dislike_nums, comment_nums, like_dislike_ratios, dates,\\\n",
    "    titles, comments, view_nums, descriptions, interactions = data\n",
    "    index = 0\n",
    "    for author_dict in comments: # video comments\n",
    "        if keyword in titles[index] or keyword in descriptions[index]:\n",
    "            vid_pos = []\n",
    "            vid_neg = []\n",
    "            vid_comp = []\n",
    "            for author in author_dict: # all the authors in the comment section\n",
    "                for comment in author_dict[author]: # their comments\n",
    "                    comp, pos, neg = analyze(comment[0])\n",
    "                    vid_pos.append(pos)\n",
    "                    vid_neg.append(neg)\n",
    "                    vid_comp.append(comp)\n",
    "            pos = statistics.mean(vid_pos)\n",
    "            neg = statistics.mean(vid_neg)\n",
    "            comp = statistics.mean(vid_comp)\n",
    "            pos_scores.append(pos)\n",
    "            neg_scores.append(neg)\n",
    "            compound_scores.append(comp)\n",
    "            dates_by_keyword.append(dates[index])\n",
    "        index+=1\n",
    "    return pos_scores,neg_scores,compound_scores,dates_by_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll retrieve the sentiment data for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pos, cnn_neg, cnn_comp, cnn_dates = analyze_channel_by_keyword(processed_cnn_data, \"Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_pos, fox_neg, fox_comp, fox_dates = analyze_channel_by_keyword(processed_fox_data, \"Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll take the sentiment data we got from our channel analysis with a keyword parameter of \"Trump\" to see how CNN viewers and Fox viewers tend to speak when the President is mentioned in or is the subject of one of their Youtube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(cnn_pos,cnn_dates, \"CNN Viewer Sentiments (Trump, positive score)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_data(fox_comp,fox_dates, \"Fox Viewer Sentiments (Trump, compound score)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(cnn_pos,cnn_dates,\"CNN Viewer Sentiments (Trump, positive score)\")\n",
    "plot_data(fox_pos,fox_dates,\"Fox Viewer Sentiments (Trump, positive score)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(cnn_neg,cnn_dates,\"CNN Viewer Sentiments (Trump, negative score)\")\n",
    "plot_data(fox_neg,fox_dates,\"Fox Viewer Sentiments (Trump, negative score)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_scores,neg_scores,compound_scores = analyze_channel(processed_cnn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datas(processed_cnn_data[3],pos_scores, \"Dislike Ratio Against Positive Sentiment Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datas(processed_cnn_data[3],neg_scores, \"Dislike Ratio Against Negative Sentiment Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datas(processed_cnn_data[3],compound_scores, \"Dislike Ratio Against Compound Sentiment Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datas(processed_cnn_data[9],compound_scores, \"Interactions vs. Compound Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Data Pre-Processing for Classification\n",
    "We'll need to tokenize our data for processing. We'll begin with tokenizing our video titles and descriptions, as they'll need to be narrowed down to keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [(processed_cnn_data, \"CNN\"),\n",
    "            (processed_fox_data, \"FOX\"),\n",
    "            (processed_msnbc_data, \"MSNBC\"),\n",
    "            (processed_breitbart_data, \"Breitbart\"),\n",
    "            (processed_nytimes_data, \"NYTimes\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of data, if we want to reduce running time, we can abbreviate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviated_data_set = []\n",
    "for data in data_set:\n",
    "    a,b,c,d,e,f,g,h,i,j = data[0]\n",
    "    channel = data[1]\n",
    "    data = a[::2],b[::2],c[::2],\\\n",
    "    d[::2],e[::2],f[::2],g[::2],\\\n",
    "    h[::2],i[::2],j[::2]\n",
    "    abbreviated_data_set.append((data,channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = []\n",
    "for data in abbreviated_data_set:\n",
    "    label_names.append(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is relatively large (certainly, it's massive for my 8GBRAM Macbook Pro), so finalizing the pre-processing might take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "def create_comment_frame(data,channel):\n",
    "    comment_list = []\n",
    "    i = 0\n",
    "    for comment_dict in data[6]: # for every video comment dictionary\n",
    "        likes = data[0][i]\n",
    "        dislikes = data[1][i]\n",
    "        comment_nums = data[2][i]\n",
    "        title = data[5][i]\n",
    "        views = data[7][i]\n",
    "        description = data[8][i]\n",
    "        for author in comment_dict: # for every author in each vid. dictionary\n",
    "            for comment in comment_dict[author]: # for all their comments\n",
    "                comment_list.append((comment[0],\n",
    "                                     comment[1],\n",
    "                                     author,\n",
    "                                     likes,\n",
    "                                     dislikes,\n",
    "                                     comment_nums,\n",
    "                                     title, \n",
    "                                     description,\n",
    "                                     views)) # append their comment and its data to the list\n",
    "        i+=1\n",
    "    pd_dict = {}\n",
    "    pd_dict['comment'] = []\n",
    "    pd_dict['commentLikes'] = []\n",
    "    pd_dict['authorName'] = []\n",
    "    pd_dict['title'] = []\n",
    "    pd_dict['description'] = []\n",
    "    pd_dict['videoLikes'] = []\n",
    "    pd_dict['videoDislikes'] = []\n",
    "    pd_dict['views'] = []\n",
    "    pd_dict['commentNum'] = []\n",
    "    for comment in comment_list:\n",
    "        pd_dict['comment'].append(comment[0])\n",
    "        pd_dict['commentLikes'].append(comment[1])\n",
    "        pd_dict['authorName'].append(comment[2])\n",
    "        pd_dict['videoLikes'].append(comment[3])\n",
    "        pd_dict['videoDislikes'].append(comment[4])\n",
    "        pd_dict['commentNum'].append(comment[5])\n",
    "        pd_dict['title'].append(comment[6])\n",
    "        pd_dict['description'].append(comment[7])\n",
    "        pd_dict['views'].append(comment[8])\n",
    "    channel_comments = pd.DataFrame.from_dict(pd_dict)\n",
    "    channel_comments['channel'] = channel\n",
    "    return channel_comments\n",
    "\n",
    "def create_comment_book_frame(data,channel):\n",
    "    video_books = []\n",
    "    i = 0\n",
    "    for comment_dict in data[6]: # for every video comment dictionary\n",
    "        book = \"\"\n",
    "        likes = data[0][i]\n",
    "        dislikes = data[1][i]\n",
    "        comment_nums = data[2][i]\n",
    "        title = data[5][i]\n",
    "        views = data[7][i]\n",
    "        description = data[8][i]\n",
    "        for author in comment_dict: # for every author in each vid. dictionary\n",
    "            for comment in comment_dict[author]: # for all their comments\n",
    "                book += \" \" + comment[0]\n",
    "        video_books.append((book, title, likes, dislikes, comment_nums, views, description))\n",
    "        i+=1\n",
    "        \n",
    "    pd_dict = {}\n",
    "    pd_dict['comments'] = []\n",
    "    pd_dict['title'] = []\n",
    "    pd_dict['description'] = []\n",
    "    pd_dict['videoLikes'] = []\n",
    "    pd_dict['videoDislikes'] = []\n",
    "    pd_dict['views'] = []\n",
    "    pd_dict['commentNum'] = []\n",
    "    for book in video_books:\n",
    "        pd_dict['comments'].append(book[0])\n",
    "        pd_dict['videoLikes'].append(book[2])\n",
    "        pd_dict['videoDislikes'].append(book[3])\n",
    "        pd_dict['commentNum'].append(book[4])\n",
    "        pd_dict['title'].append(book[1])\n",
    "        pd_dict['description'].append(book[6])\n",
    "        pd_dict['views'].append(book[5])\n",
    "    channel_comments = pd.DataFrame.from_dict(pd_dict)\n",
    "    channel_comments['channel'] = channel\n",
    "    return channel_comments\n",
    "\n",
    "def create_dataset_dataframe(dataset,bit):\n",
    "    if bit == 1:\n",
    "        frame = create_comment_frame(dataset[0][0], dataset[0][1])\n",
    "        for data in dataset[1:]:\n",
    "            frame = pd.concat([frame,create_comment_frame(data[0], data[1])]).sample(frac=1).reset_index(drop=True)\n",
    "        return frame\n",
    "    else:\n",
    "        frame = create_comment_book_frame(dataset[0][0], dataset[0][1])\n",
    "        for data in dataset[1:]:\n",
    "            frame = pd.concat([frame,create_comment_book_frame(data[0], data[1])]).sample(frac=1).reset_index(drop=True)\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_dataframe = create_dataset_dataframe(data_set,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>videoLikes</th>\n",
       "      <th>videoDislikes</th>\n",
       "      <th>views</th>\n",
       "      <th>commentNum</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greed, politicans that lie to the citizens, p...</td>\n",
       "      <td>Chuck Schumer: Senators can work longer hours ...</td>\n",
       "      <td>CNN's Wolf Blitzer and Jake Tapper talk to Sen...</td>\n",
       "      <td>1377</td>\n",
       "      <td>854</td>\n",
       "      <td>135355</td>\n",
       "      <td>2278</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this Woman and ukelle both are equally annoyi...</td>\n",
       "      <td>Have The Dating Blues? #MeToo | NYT Op-Ed</td>\n",
       "      <td>The #MeToo movement has changed the public con...</td>\n",
       "      <td>328</td>\n",
       "      <td>3197</td>\n",
       "      <td>31830</td>\n",
       "      <td>814</td>\n",
       "      <td>NYTimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean hannity you are perfect definition of  a...</td>\n",
       "      <td>Sean Hannity previews his interview with Trump...</td>\n",
       "      <td>Sean Hannity, host of ‘Hannity', previews his ...</td>\n",
       "      <td>5527</td>\n",
       "      <td>404</td>\n",
       "      <td>358423</td>\n",
       "      <td>1555</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake virus.... Watch WACO Netflix. Our growth...</td>\n",
       "      <td>Trump Lauds Testing Efforts, But Under 1% Of T...</td>\n",
       "      <td>Talking up the job his administration has been...</td>\n",
       "      <td>4004</td>\n",
       "      <td>485</td>\n",
       "      <td>423504</td>\n",
       "      <td>3171</td>\n",
       "      <td>MSNBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah.....Not getting a mandatory vaccine. Som...</td>\n",
       "      <td>When Is The Right Time To Lift Lockdown Measur...</td>\n",
       "      <td>NBC's Ron Allen reports on the situation in Ne...</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>21256</td>\n",
       "      <td>225</td>\n",
       "      <td>MSNBC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0   Greed, politicans that lie to the citizens, p...   \n",
       "1   this Woman and ukelle both are equally annoyi...   \n",
       "2   Sean hannity you are perfect definition of  a...   \n",
       "3   Fake virus.... Watch WACO Netflix. Our growth...   \n",
       "4   Yeah.....Not getting a mandatory vaccine. Som...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chuck Schumer: Senators can work longer hours ...   \n",
       "1          Have The Dating Blues? #MeToo | NYT Op-Ed   \n",
       "2  Sean Hannity previews his interview with Trump...   \n",
       "3  Trump Lauds Testing Efforts, But Under 1% Of T...   \n",
       "4  When Is The Right Time To Lift Lockdown Measur...   \n",
       "\n",
       "                                         description  videoLikes  \\\n",
       "0  CNN's Wolf Blitzer and Jake Tapper talk to Sen...        1377   \n",
       "1  The #MeToo movement has changed the public con...         328   \n",
       "2  Sean Hannity, host of ‘Hannity', previews his ...        5527   \n",
       "3  Talking up the job his administration has been...        4004   \n",
       "4  NBC's Ron Allen reports on the situation in Ne...         220   \n",
       "\n",
       "   videoDislikes   views  commentNum  channel  \n",
       "0            854  135355        2278      CNN  \n",
       "1           3197   31830         814  NYTimes  \n",
       "2            404  358423        1555      FOX  \n",
       "3            485  423504        3171    MSNBC  \n",
       "4             19   21256         225    MSNBC  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Classification\n",
    "So we have our dataframes all loaded up! Pandas is great because it allows us to perform vectorized operations on our data, which is fairly dense. We will divide our dataframe into a training and test set and we will create text embeddings for our features. I've adapted some code used for sentiment analysis to suit our purposes. I've organized things so that our model considers each comment's content and its context (so the actual language and the title, description, and statistics of the video it was left on. The model treats the channel names as labels, so when it is trained and shown comments, it can make predictions about which channel the comments originated from. Here, we will first train the model to try to recognize channel origins for just singular comments. Then, we will merge comments to form a corpus of comment-books for each video, treating a video as though it were an author of a book of all of its comments, and we will try to train the model to recognize which channel a body of comments came from.\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "\n",
    "We will be using a Deep Neural Network classifier from TensorFlow. The folks at Google's TensorFlow Hub put together a Jupyter notebook in which they trained a classifier to classify sentiment polarity in movie reviews. I adapted this model so that it can use multiple labels (our channel names), and multiple features (the fields from our dataframes, which I created from our processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(all_comments_dataframe, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll divide our dataframe into a test set and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the whole training set.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"channel\"], num_epochs=None, shuffle=True)\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"channel\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    test_df, test_df[\"channel\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll create embeddings for all our features: comments, video descriptions, the number of likes for each comment, the author of the comment, and the title of the video the comment was left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"comments\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "embedded_text_feature_column2 = hub.text_embedding_column(\n",
    "    key=\"description\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "embedded_text_feature_column5 = hub.text_embedding_column(\n",
    "    key=\"title\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass our feautures and labels to a TensorFlow DNN estimator and fire up the estimator so that we can run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    feature_columns=[embedded_text_feature_column,\n",
    "                     embedded_text_feature_column2,\n",
    "                     embedded_text_feature_column5],\n",
    "    label_vocabulary = label_names,\n",
    "    n_classes=5,\n",
    "    optimizer=tf.keras.optimizers.Adagrad(lr=0.003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7252691, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7252691, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.33364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.33364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.97386545, step = 100 (42.859 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.97386545, step = 100 (42.859 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5783602, step = 200 (37.446 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5783602, step = 200 (37.446 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43759573, step = 300 (37.603 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43759573, step = 300 (37.603 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.31392676, step = 400 (37.322 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.31392676, step = 400 (37.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.252106, step = 500 (37.532 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.252106, step = 500 (37.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.69803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.69803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2262139, step = 600 (37.064 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2262139, step = 600 (37.064 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.71163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.71163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23036945, step = 700 (36.878 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23036945, step = 700 (36.878 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16381823, step = 800 (37.317 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16381823, step = 800 (37.317 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.63566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.63566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14970866, step = 900 (37.941 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14970866, step = 900 (37.941 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.64914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.64914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15964068, step = 1000 (37.748 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15964068, step = 1000 (37.748 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.71042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.71042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17304876, step = 1100 (36.895 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17304876, step = 1100 (36.895 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11914586, step = 1200 (37.416 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11914586, step = 1200 (37.416 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.09509199, step = 1300 (37.198 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.09509199, step = 1300 (37.198 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.2792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10391707, step = 1400 (43.876 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10391707, step = 1400 (43.876 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07695952, step = 1500 (40.921 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07695952, step = 1500 (40.921 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1556 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1556 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.60304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.60304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05182898, step = 1600 (62.397 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05182898, step = 1600 (62.397 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.15968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.15968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07423025, step = 1700 (46.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07423025, step = 1700 (46.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.36056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.36056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.044146284, step = 1800 (42.361 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.044146284, step = 1800 (42.361 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.97895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.97895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.101576924, step = 1900 (50.538 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.101576924, step = 1900 (50.538 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.26422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.26422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.032313224, step = 2000 (44.154 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.032313224, step = 2000 (44.154 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.73823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.73823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.040047675, step = 2100 (36.521 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.040047675, step = 2100 (36.521 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.60687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.60687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.029248774, step = 2200 (38.360 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.029248774, step = 2200 (38.360 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.054092903, step = 2300 (40.532 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.054092903, step = 2300 (40.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.55235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.55235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04295983, step = 2400 (39.180 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04295983, step = 2400 (39.180 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.050766356, step = 2500 (40.145 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.050766356, step = 2500 (40.145 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.52613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.52613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03813941, step = 2600 (39.587 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03813941, step = 2600 (39.587 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.50502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.50502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07036524, step = 2700 (39.920 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07036524, step = 2700 (39.920 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.63238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.63238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04180754, step = 2800 (37.987 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04180754, step = 2800 (37.987 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.73256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.73256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05719939, step = 2900 (36.596 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05719939, step = 2900 (36.596 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2979 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2979 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.6533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.022114009, step = 3000 (60.491 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.022114009, step = 3000 (60.491 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03885308, step = 3100 (40.950 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03885308, step = 3100 (40.950 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.43422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.43422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.050759334, step = 3200 (41.079 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.050759334, step = 3200 (41.079 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.029696465, step = 3300 (40.673 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.029696465, step = 3300 (40.673 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05705505, step = 3400 (40.050 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.05705505, step = 3400 (40.050 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.047060978, step = 3500 (40.071 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.047060978, step = 3500 (40.071 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019732103, step = 3600 (40.532 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019732103, step = 3600 (40.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.48372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.48372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.021713136, step = 3700 (40.262 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.021713136, step = 3700 (40.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.036205985, step = 3800 (40.302 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.036205985, step = 3800 (40.302 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.48317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.48317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.02626045, step = 3900 (40.271 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.02626045, step = 3900 (40.271 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.50247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.50247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04717797, step = 4000 (39.960 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04717797, step = 4000 (39.960 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.034420393, step = 4100 (40.814 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.034420393, step = 4100 (40.814 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.53636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.53636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.027850527, step = 4200 (39.442 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.027850527, step = 4200 (39.442 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.52505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.52505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.051915877, step = 4300 (39.588 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.051915877, step = 4300 (39.588 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.30963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.30963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01232448, step = 4400 (43.297 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01232448, step = 4400 (43.297 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4403 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4403 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.63516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.63516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04521504, step = 4500 (61.156 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04521504, step = 4500 (61.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.43518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.43518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019795615, step = 4600 (41.064 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019795615, step = 4600 (41.064 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.042766977, step = 4700 (40.886 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.042766977, step = 4700 (40.886 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.39666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.39666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.016674668, step = 4800 (41.724 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.016674668, step = 4800 (41.724 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.47458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.47458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.010504802, step = 4900 (40.412 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.010504802, step = 4900 (40.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "/var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt-5000_temp_d949582bad1d483f80e2993e1afc5f6f/part-00001-of-00002.data-00000-of-00001.tempstate11358327433404491680; No space left on device\n\t [[node save_6/SaveV2_1 (defined at /Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py:1493) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'save_6/SaveV2_1':\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-335-b7f6c315dc0e>\", line 1, in <module>\n    estimator.train(input_fn=train_input_fn, steps=5000);\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1198, in _train_model_default\n    saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1493, in _train_with_estimator_spec\n    log_step_count_steps=log_step_count_steps) as mon_sess:\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 604, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1038, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 749, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1231, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1236, in _create_session\n    return self._sess_creator.create_session()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 902, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 660, in create_session\n    self._scaffold.finalize()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 243, in finalize\n    self._saver.build()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 499, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 291, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 265, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 206, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 122, in save_op\n    tensors)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1717, in save_v2\n    name=name)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1352\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt-5000_temp_d949582bad1d483f80e2993e1afc5f6f/part-00001-of-00002.data-00000-of-00001.tempstate11358327433404491680; No space left on device\n\t [[{{node save_6/SaveV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-b7f6c315dc0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1196\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1197\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1496\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m       logging.warning('Training with estimator made no steps. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m     \u001b[0;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[0;34m(self, exception_type)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m           \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mend\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_step_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_triggered_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listeners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, session, step)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     self._get_saver().save(session, self._save_path, global_step=step,\n\u001b[0;32m--> 619\u001b[0;31m                            write_meta_graph=self._save_graph_def)\n\u001b[0m\u001b[1;32m    620\u001b[0m     self._summary_writer.add_session_log(\n\u001b[1;32m    621\u001b[0m         SessionLog(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[1;32m   1174\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1175\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 960\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1183\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1361\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1386\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /var/folders/tn/fcl1261n75l3455rc43h8df80000gn/T/tmp4vw0rguq/model.ckpt-5000_temp_d949582bad1d483f80e2993e1afc5f6f/part-00001-of-00002.data-00000-of-00001.tempstate11358327433404491680; No space left on device\n\t [[node save_6/SaveV2_1 (defined at /Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py:1493) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'save_6/SaveV2_1':\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-335-b7f6c315dc0e>\", line 1, in <module>\n    estimator.train(input_fn=train_input_fn, steps=5000);\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1198, in _train_model_default\n    saving_listeners)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1493, in _train_with_estimator_spec\n    log_step_count_steps=log_step_count_steps) as mon_sess:\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 604, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1038, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 749, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1231, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1236, in _create_session\n    return self._sess_creator.create_session()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 902, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 660, in create_session\n    self._scaffold.finalize()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 243, in finalize\n    self._saver.build()\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 499, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 291, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 265, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 206, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 122, in save_op\n    tensors)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1717, in save_v2\n    name=name)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/Users/jaredprior/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=5000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem too good to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = {}\n",
    "test_dataframe['comment'] = []\n",
    "test_dataframe['commentLikes'] = []\n",
    "test_dataframe['authorName'] = []\n",
    "test_dataframe['title'] = []\n",
    "test_dataframe['description'] = []\n",
    "test_dataframe['videoLikes'] = []\n",
    "test_dataframe['videoDislikes'] = []\n",
    "test_dataframe['views'] = []\n",
    "test_dataframe['commentNum'] = []\n",
    "test_dataframe['channel'] = []\n",
    "comment_list = [[\"This is the DUMBEST president ever in HISTORY! 🤔\",\n",
    "                 80,\n",
    "                 \"MagicSantos\",\n",
    "                 452,\n",
    "                 53,\n",
    "                 383,\n",
    "                 \"Trump explains why he plans to wind down the coronavirus task force\",\n",
    "                 \"CNN's Anderson Cooper reports that President Donald Trump plans to wind down the coronavirus task force near the end of May. #CNN #News\",\n",
    "                 4970],\n",
    "                [\"Every move trump makes is against our people. Are we sure he’s not a Russian?\",\n",
    "                 77,\"Blue\",\n",
    "                 452,53,383,\n",
    "                 \"Trump explains why he plans to wind down the coronavirus task force\",\n",
    "                 \"CNN's Anderson Cooper reports that President Donald Trump plans to wind down the coronavirus task force near the end of May. #CNN #News\",\n",
    "                 4970]]\n",
    "for comment in comment_list:\n",
    "    test_dataframe['comment'].append(comment[0])\n",
    "    test_dataframe['commentLikes'].append(comment[1])\n",
    "    test_dataframe['authorName'].append(comment[2])\n",
    "    test_dataframe['videoLikes'].append(comment[3])\n",
    "    test_dataframe['videoDislikes'].append(comment[4])\n",
    "    test_dataframe['commentNum'].append(comment[5])\n",
    "    test_dataframe['title'].append(comment[6])\n",
    "    test_dataframe['description'].append(comment[7])\n",
    "    test_dataframe['views'].append(comment[8])\n",
    "    test_dataframe['channel'].append(\"CNN\")\n",
    "test_dataframe = pd.DataFrame.from_dict(test_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn=testfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
